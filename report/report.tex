\documentclass{article}
\usepackage{graphicx}
\usepackage{fullpage}

\title{Approaches to Scamming PageRank}
\author{Manu Goyal, Don-Wook Shin, Luvsanbyamba Buyankhuu}
\date{\today}

\begin{document}

\maketitle

\section*{Introduction}

The PageRank algorithm we studied in class is an effective way to sort pages by
their relative importance. Unfortunately, there are numerous ways malicious
users can modify the network in order to artificially increase the PageRank
score of desired pages. We explore different exploitations of PageRank in the
context of the Simple English Wikipedia network.

\section*{Methods}

We chose to use the Simple English Wikipedia network of pages, because it was a
somewhat large, real-world dataset, but wasn't so large that experimenting with
the data would become too cumbersome. The first thing we did was to calculate
PageRank on the entire wikipedia network, using the standard PageRank algorithm
(which we found on Wikipedia). After looking over the results we got, we devised
two ways to scam the PageRank algorithm, to boost the rank of a specific page.

\subsection*{Method 1: Create Links From Important Pages}

This method is fairly straightforward. Since the rank of a page improves when
other pages with a high rank link to it, somebody could easily improve the rank
of a given Wikipedia page by linking other important pages to it.

To see exactly how much this would improve the score, let $\pi_l$ be the rank of
a low-ranked page, and $\pi_h$ be the rank of a high-ranked page that we will
add a link to. Initially, after PageRank has converged $\pi_l$ will satisfy the
equation $\pi_l = (1 - d) + d(\sum_{i=0}^n \frac{\pi_i}{L(i)})$, where $d$ is a
damping factor for successive iterations of PageRank, $\pi_0 \ldots \pi_n$ are
the ranks of pages that link to $l$, and $L(i)$ is the number of outbound links
for page $i$. Then adding a link from page $h$ would make the rank of $l$
approximately
$(1 - d) + d(\sum_{i=0}^n \frac{\pi_i}{L(i)} + frac{\pi_h}{L(h)+1})$, which is a
difference of $d \frac{\pi_h}{L(h)+1}$. It is important to note that this is not
an exact difference, because adding a link in the network will change the
pageranks of everything else, so the effect on $l$ will be slightly different.
However, as we'll see, this estimate is usually very close to the actual change
in pagerank.

We built a tool, that, given a wikipedia page and a target page rank to improve
to, will suggest a series of pages to add links to, in order to boost the
pagerank to the desired amount. The effectiveness of this tool is explored in
the next section.

\subsection*{Method 2: Create New Pages with High Page Ranks}

While the previous approach operated under the assumption that the malicious user 
had only access to the pages that could be edited by any public user, we now consider 
the situation where the malicious user has "admin access", e.g. has access to pages
that may not be editable by the general public. These pages- including topics such as 
Barack Obama, the United States, or Computers- tend to have very high page ranks.
Whereas in the previous method, we may have to manipulate and create links in an arbitrarily
large number of pages, this method allows us to inflate the page rank of the target page more efficiently.

\subsection*{Discussion of Other Methods}

One of the restrictions Wikipedia places on its articles is that a page can link to another at most once. 
We can sidestep this restriction and in essence create multiple links on one page to another by inserting artificial pages
that serve as placeholders. As explained in method 1, the pagerank of the page would be increased by $d \frac{\pi_h}{L(h)+1}$
per each link. Given $n$ new pages artificially created, we could amplify the pagerank effect by a factor of $n$.

\section*{Evaluation}

\subsection*{Method 1}

The pageranks we obtained ranged from 1 to about 38,000. We ran our tool on
pages with ranks 10, 100, 1000, and 10000, and tried to boost
them each to 1000, 10000, and 100000. We first examine the number of edits necessary for each boost. \\

\includegraphics[width=8cm]{EditsPerBoost}

Since there were a number of Wikipedia pages with large existing pageranks, it
didn't take a lot of edits to boost pageranks up to 1000 or 10000, only 1 or 2
edits on average. However, when we wanted to boost up to a rank of 100000, we
needed to edit over 1000 pages on average, primarily because there were only a
few pages that could boost our rank by over 5000, so we needed a lot of less
significant pages to get up to 100000. \\

\includegraphics[width=8cm]{PageRank10Boost} \includegraphics[width=8cm]{PageRank100Boost} \\

Above, we compare the expected and actual boost we got from implementing our
edits, if we started with page ranks 10 and 100 (the graphs for 1000 and 10000
are in the folder, but not in the report for brevity). In both scenarios, our
actual boost exceeded the expected boost when we wanted to increase to 1000 or
10000 (some very large boosts are due to the fact that the algorithm starts by
picking the page that would give the largest boost, rather than the one that
would give a boost closest to what is desired), but when we wanted to increase
to 100000, we fell short slightly. Again, due to the lack of pages that could
lend very large scores to our target pages, we weren't able to reach up to
100000, but the algorithm gets very close.

\subsection*{Method 2}
The results of this method are similar to method 1's, but as expected, requires
fewer pages and links, since the efficacy of each link is increased do to the
higher pageranks. For brevity, we leave out the detailed analysis, which can be
obtained in a manner almost mirrored to that in method 1.

\section*{Discussion and Counter-Measures}

Our automated tool for method 1 ended up performing very close to what was
expected. Even though it uses rough calculations to estimate how much linking
pages will affect the pagerank, they tend to be fairly close to the expected
boost, which, in some ways, demonstrates the volatility of the pagerank
algorithm. By adding a very small number of links, we can change the page rank
of specific pages by enormous amounts. The major drawback to this method is that
it is hard to implement in a context outside of wikipedia, where editing large
numbers of important pages is not very feasible.

When considering possible counter measures to page rank inflation, we considered
any abnormalities that would differentiate an inflated page to a normal one.
Obviously, being able to compare a before and after image of the wiki would
provide a trivial solution, so we strove to find solutions that instead only
look at the current state. The two solutions we found are explained as followed.

First, we realized that our first method would result in a page that is not
actually related in content to the pages it is linked by. For example, our
method may create a link in the "Surfing" page to "Chocolate Muffins" based on
the fact that "Surfing" has a high pagerank and will increase the latter
substantially. By counting the number of alternate paths from one page to
another, we can assess how related two pages actually are.

Second, we realized that if we consider the pages linking to an authentically
high pageranked page, these pages will have pageranks that are fairly evenly
distributed. That is, a high ranked page will be linked to by both high ranked
and low ranked pages. An artificially inflated page however, will be skewed with
pages that are high as well. Therefore, we penalize pages that have an unusually
high number of backlinks coming from very highly-ranked pages, since they are
more likely to be artificially constructed.


\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
